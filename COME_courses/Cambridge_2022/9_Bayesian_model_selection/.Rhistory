record_log_posterior <- c()
record_log_posterior <- c(record_log_posterior, current_log_posterior)
# We also record the likelihood:
current_log_likelihood <- log_likelihood(data = data, lambda = current_parameter_value, power=likelihood_power)
record_log_likelihood <- c()
record_log_likelihood <- c(record_log_likelihood, current_log_likelihood)
for (i in 1:number_iterations) {
acceptance_threshold <- runif(min=0, max=1, n=1)
proposed_parameter_value <- propose_new_lambda_value()
proposed_log_posterior = unnormalized_log_posterior(data = data, lambda = proposed_parameter_value, power=likelihood_power)
# print(paste0(proposed_log_posterior, " vs ", current_log_posterior))
if (exp(proposed_log_posterior - current_log_posterior) > acceptance_threshold) {
current_parameter_value <- proposed_parameter_value
current_log_posterior <- proposed_log_posterior
current_log_likelihood <- log_likelihood(data = data, lambda = current_parameter_value, power=likelihood_power)
}
record_parameter <- c(record_parameter, current_parameter_value)
record_log_posterior <-c(record_log_posterior, current_log_posterior)
record_log_likelihood <- c(record_log_likelihood, current_log_likelihood)
}
to_discard_as_burnin <- floor(burnin_proportion * number_iterations)
num_samples_left <- number_iterations - to_discard_as_burnin
between_samples <- floor(num_samples_left / (num_samples_left * thining_proportion))
record_parameter <- record_parameter[(to_discard_as_burnin+1):number_iterations][seq(from=1, to=num_samples_left, by=between_samples)]
record_log_posterior <- record_log_posterior[(to_discard_as_burnin+1):number_iterations][seq(from=1, to=num_samples_left, by=between_samples)]
record_log_likelihood <- record_log_likelihood[(to_discard_as_burnin+1):number_iterations][seq(from=1, to=num_samples_left, by=between_samples)]
return (list(record_parameter, record_log_posterior, record_log_likelihood))
}
mcmc_sample <- MetropolisMCMC(data=n_letters, number_iterations=10000, likelihood_power=1.0, burnin_proportion=0.5, thining_proportion=0.01)
harmonic_mean <- function(mcmc_sample) {
loglks <- mcmc_sample[[3]]
min_loglk <- min(loglks)
scaled_loglks <- loglks - min_loglk + 1
number_of_samples <- length(loglks)
marginal_lk <- log(number_of_samples) - log( sum(exp(-scaled_loglks))) + min_loglk - 1
return(marginal_lk)
}
harmonic_mean(mcmc_sample)
par(mfrow=c(5,1))
plotDistributions(1.0)
plotDistributions(0.5)
plotDistributions(0.25)
plotDistributions(0.125)
plotDistributions(0.06275)
steppingStoneSampling <- function (vector_powers, data, number_iterations, burnin_proportion=0.5, thining_proportion=0.1) {
number_of_stones = length(vector_powers)
number_of_samples_per_stone = floor(number_iterations - floor(burnin_proportion*number_iterations)) * thining_proportion
sampled_values <-matrix(rep(number_of_stones*number_of_samples_per_stone), nrow=number_of_stones, ncol=number_of_samples_per_stone, byrow=TRUE)
for (i in 1:number_of_stones) {
sampled_values[i,] <- MetropolisMCMC(data, number_iterations, burnin_proportion=0.5, thining_proportion=0.1, likelihood_power=vector_powers[i])[[2]]
}
return(sampled_values)
}
compute_marginal_lk_from_SS_samples <- function (ss_samples) {
number_of_stones = dim(ss_samples)[1]
number_of_samples = dim(ss_samples)[2]
c_values <- rep(0, number_of_stones)
for (i in 1:number_of_stones) {
c_values[i] <- logSumExp(ss_samples[i,])
}
logratios <- rep(0, number_of_stones-1)
for (i in 1:(number_of_stones-1)) {
logratios[i] <- c_values[i+1]-c_values[i]
}
return(sum(logratios))
}
build_vector_powers <- function (alpha=0.3, beta=1.0, number_of_stones=10) {
vector_powers <- rep(0.0, 10)
for (i in 1:number_of_stones) {
vector_powers[i]<-(i/number_of_stones)^(beta/alpha)
}
return(vector_powers)
}
vector_powers <- build_vector_powers ()
SS_samples <- steppingStoneSampling(vector_powers=vector_powers, data=n_letters, number_iterations=1000, burnin_proportion=0.5, thining_proportion=0.1)
compute_marginal_lk_from_SS_samples(SS_samples)
SS_samples <- steppingStoneSampling(vector_powers=vector_powers, data=n_letters, number_iterations=10000, burnin_proportion=0.5, thining_proportion=0.1)
compute_marginal_lk_from_SS_samples(SS_samples)
vector_powers <- build_vector_powers (number_of_stones = 100)
SS_samples <- steppingStoneSampling(vector_powers=vector_powers, data=n_letters, number_iterations=1000, burnin_proportion=0.5, thining_proportion=0.1)
compute_marginal_lk_from_SS_samples(SS_samples)
lambda_sample <- seq(1:1000000)/1000
unnormalized_marginal_likelihood <- logSumExp(sapply(X=lambda_sample, FUN=log_likelihood, data=n_letters))
print(unnormalized_marginal_likelihood)
vector_powers <- build_vector_powers (number_of_stones = 100)
SS_samples <- steppingStoneSampling(vector_powers=vector_powers, data=n_letters, number_iterations=10000, burnin_proportion=0.5, thining_proportion=0.1)
compute_marginal_lk_from_SS_samples(SS_samples)
lambda_sample <- seq(1:100000)/100
unnormalized_marginal_likelihood <- logSumExp(sapply(X=lambda_sample, FUN=log_likelihood, data=n_letters)) - length(lambda_sample)
print(unnormalized_marginal_likelihood)
lambda_sample <- seq(1:100000)/100
unnormalized_marginal_likelihood <- logSumExp(sapply(X=lambda_sample, FUN=log_likelihood, data=n_letters)) - log(length(lambda_sample))
print(unnormalized_marginal_likelihood)
library(matrixStats)
n_letters <- c(13,17,14,10,13,16,14,14,11,14,9,14,13,10,11,12,17,15,23,16,13,14,12,16,15,19,14,11,15,14,17,20,27,21,12,6,18,10,8,12,11,14,14,15,16,17,12,13,17,10,16,20,15,12,24,10,17,14,14,13,15,12,14,17,9,16,27,10,16,9,15,11,16,11,17,17,11,20,23,12,18,26,12,17,16,12,11,16,21,19,20,19,15,15,7,14,12,12,15,10,19,19,17,15,17,20,17,17,11,11,17,16,15,12,16,17,14,18,15,15,10,17,12,16,22,20,23,16,11,19,16,22,13,14,11,10,19,16,19,15,16,16,16,19,14,19,14,10,7,11,12,9,13,18,23,13,16,11,15,13,15,19,16,21,14,14,14,12,15,16,18,15,15,13,15,19,11,17,13,9,13,16,16,13,13,13,18,21,14,14,13,8,21,20,15,20,10,16,18,14,21,15,20,15,15,9,16,16,11,19,12,31,19,18,13,11,14,14,11,10,11,12,13,17,14,14,25,17,18,16,18,11,23,23,14,14,11,17,11,12,18,15,15,13,16,18,15,16,14,11,11,17,18,14,20,17,16,13,12,14,14,18,16,21,16,15,18,19,22,16,15,10,12,11,9,18,11,13,5,13,16,14,12,23,19,14,17,11,17,18,17,16,11,22,18,20,11,12,9,8,12,12,17,16,12,20,19,15,9,14,11,13,13,23,16,10,17,14,20,11,20,15,20,15,19,19,16,15,14,18,24,18,12,16,10,18,16,19,13,13,13,22,13,15,17,17,20,18,18,12,13,14,17,15,17,20,18,22,23,13,16,15,18,10,19,12,14,19,14,19,23,19,22,8,14,20,22,14,13,13,9,11,13,14,16,16,16,14,16,24,11,10,14,14,14,18,15,11,12,15,16,13,8,13,21,19,17,18,10,14,14,16,14,11,14,12,15,9,17,17,21,11,8,22,18,18,23,20,14,10,15,10,18,12,10,18,17,18,18,9,15,18,15,15,17,15,18,16,9,16,15,10,18,18,19,8,18,17,10,11,17,12,14,16,14,10,10,20,16,11,15,14,15,21,15,21,16,17,18,12,14,10,13,17,12,14,26,23,20,12,21,17,11,12,12,11,15,19,15,12,15,12,21,13,19,17,18,17,11,22,17,13,11,16,16,10,17,14,17,18)
log_prior <- function (lambda) {
return (dunif(x=lambda, min=0, max=1000, log=TRUE))
}
log_likelihood <- function (data, lambda, power=1) {
return (sum(dpois(x=data, lambda=lambda, log=TRUE))*power)
}
likelihood <- function (data, lambda, power=1) {
return (prod(dpois(x=data, lambda=lambda, log=FALSE))^power)
}
unnormalized_log_posterior <- function (data, lambda, power=1) {
log_prior_value <- log_prior(lambda=lambda)
log_likelihood_value <- log_likelihood(data=data, lambda=lambda, power=power)
return(log_prior_value + log_likelihood_value)
}
plotDistributions <- function (power) {
x_axis <- seq(1:1000)#/1000
min_max= quantile(x=c(sapply(X=x_axis, FUN=log_likelihood, data=n_letters, power=1.0), sapply(X=x_axis, FUN=log_prior), sapply(X=x_axis, FUN=unnormalized_log_posterior, data=n_letters, power=1.0)), probs=c(0,1))
plot(x=x_axis, y=sapply(X=x_axis, FUN=log_likelihood, data=n_letters, power=power), t="l", lwd=4, col="red", ylim=c(min_max[1], min_max[2]), ylab="Value", xlab="lambda value", cex=2)
lines(x=x_axis, y=sapply(X=x_axis, FUN=log_prior), lwd=2, col="black")
lines(x=x_axis, y=sapply(X=x_axis, FUN=unnormalized_log_posterior, data=n_letters, power=power), lwd=2, col="orange")
legend("bottomleft", legend=c("log-likelihood", "log-prior", "log-posterior"), col=c("red", "black", "orange"), lwd=2)
}
plotDistributions(power=1.0)
lambda_sample <- seq(1:100000)/100
unnormalized_marginal_likelihood <- logSumExp(sapply(X=lambda_sample, FUN=log_likelihood, data=n_letters)) - log(length(lambda_sample))
print(unnormalized_marginal_likelihood)
# Function to propose a new parameter value, randomly drawn between 0 and 1000
propose_new_lambda_value <-function() {
return (runif(min=0, max=1000, n=1))
}
# Function to run Metropolis MCMC inference
MetropolisMCMC <- function (data, number_iterations, burnin_proportion=0.5, thining_proportion=0.1, likelihood_power=1.0) {
current_parameter_value <- propose_new_lambda_value()
record_parameter <- c()
record_parameter <- c(record_parameter,current_parameter_value)
#print(paste("Initial parameter value for the MCMC: ", current_parameter_value, sep=""))
current_log_posterior <- unnormalized_log_posterior(data = data, lambda = current_parameter_value, power=likelihood_power)
#print(paste("Initial probability of the model: ", current_log_posterior, sep=""))
record_log_posterior <- c()
record_log_posterior <- c(record_log_posterior, current_log_posterior)
# We also record the likelihood:
current_log_likelihood <- log_likelihood(data = data, lambda = current_parameter_value, power=likelihood_power)
record_log_likelihood <- c()
record_log_likelihood <- c(record_log_likelihood, current_log_likelihood)
for (i in 1:number_iterations) {
acceptance_threshold <- runif(min=0, max=1, n=1)
proposed_parameter_value <- propose_new_lambda_value()
proposed_log_posterior = unnormalized_log_posterior(data = data, lambda = proposed_parameter_value, power=likelihood_power)
# print(paste0(proposed_log_posterior, " vs ", current_log_posterior))
if (exp(proposed_log_posterior - current_log_posterior) > acceptance_threshold) {
current_parameter_value <- proposed_parameter_value
current_log_posterior <- proposed_log_posterior
current_log_likelihood <- log_likelihood(data = data, lambda = current_parameter_value, power=likelihood_power)
}
record_parameter <- c(record_parameter, current_parameter_value)
record_log_posterior <-c(record_log_posterior, current_log_posterior)
record_log_likelihood <- c(record_log_likelihood, current_log_likelihood)
}
to_discard_as_burnin <- floor(burnin_proportion * number_iterations)
num_samples_left <- number_iterations - to_discard_as_burnin
between_samples <- floor(num_samples_left / (num_samples_left * thining_proportion))
record_parameter <- record_parameter[(to_discard_as_burnin+1):number_iterations][seq(from=1, to=num_samples_left, by=between_samples)]
record_log_posterior <- record_log_posterior[(to_discard_as_burnin+1):number_iterations][seq(from=1, to=num_samples_left, by=between_samples)]
record_log_likelihood <- record_log_likelihood[(to_discard_as_burnin+1):number_iterations][seq(from=1, to=num_samples_left, by=between_samples)]
return (list(record_parameter, record_log_posterior, record_log_likelihood))
}
mcmc_sample <- MetropolisMCMC(data=n_letters, number_iterations=10000, likelihood_power=1.0, burnin_proportion=0.5, thining_proportion=0.01)
harmonic_mean <- function(mcmc_sample) {
loglks <- mcmc_sample[[3]]
min_loglk <- min(loglks)
scaled_loglks <- loglks - min_loglk + 1
number_of_samples <- length(loglks)
marginal_lk <- log(number_of_samples) - log( sum(exp(-scaled_loglks))) + min_loglk - 1
return(marginal_lk)
}
harmonic_mean(mcmc_sample)
par(mfrow=c(5,1))
plotDistributions(1.0)
plotDistributions(0.5)
plotDistributions(0.25)
plotDistributions(0.125)
plotDistributions(0.06275)
steppingStoneSampling <- function (vector_powers, data, number_iterations, burnin_proportion=0.5, thining_proportion=0.1) {
number_of_stones = length(vector_powers)
number_of_samples_per_stone = floor(number_iterations - floor(burnin_proportion*number_iterations)) * thining_proportion
sampled_values <-matrix(rep(number_of_stones*number_of_samples_per_stone), nrow=number_of_stones, ncol=number_of_samples_per_stone, byrow=TRUE)
for (i in 1:number_of_stones) {
sampled_values[i,] <- MetropolisMCMC(data, number_iterations, burnin_proportion=0.5, thining_proportion=0.1, likelihood_power=vector_powers[i])[[2]]
}
return(sampled_values)
}
compute_marginal_lk_from_SS_samples <- function (ss_samples) {
number_of_stones = dim(ss_samples)[1]
number_of_samples = dim(ss_samples)[2]
c_values <- rep(0, number_of_stones)
for (i in 1:number_of_stones) {
c_values[i] <- logSumExp(ss_samples[i,])
}
logratios <- rep(0, number_of_stones-1)
for (i in 1:(number_of_stones-1)) {
logratios[i] <- c_values[i+1]-c_values[i]
}
return(sum(logratios))
}
build_vector_powers <- function (alpha=0.3, beta=1.0, number_of_stones=10) {
vector_powers <- rep(0.0, 10)
for (i in 1:number_of_stones) {
vector_powers[i]<-(i/number_of_stones)^(beta/alpha)
}
return(vector_powers)
}
vector_powers <- build_vector_powers ()
SS_samples <- steppingStoneSampling(vector_powers=vector_powers, data=n_letters, number_iterations=1000, burnin_proportion=0.5, thining_proportion=0.1)
compute_marginal_lk_from_SS_samples(SS_samples)
SS_samples <- steppingStoneSampling(vector_powers=vector_powers, data=n_letters, number_iterations=10000, burnin_proportion=0.5, thining_proportion=0.1)
compute_marginal_lk_from_SS_samples(SS_samples)
vector_powers <- build_vector_powers (number_of_stones = 100)
SS_samples <- steppingStoneSampling(vector_powers=vector_powers, data=n_letters, number_iterations=1000, burnin_proportion=0.5, thining_proportion=0.1)
compute_marginal_lk_from_SS_samples(SS_samples)
vector_powers <- build_vector_powers (number_of_stones = 100)
SS_samples <- steppingStoneSampling(vector_powers=vector_powers, data=n_letters, number_iterations=10000, burnin_proportion=0.5, thining_proportion=0.1)
compute_marginal_lk_from_SS_samples(SS_samples)
harmonic_mean(mcmc_sample)
subset_posterior <- sample(mcmc_sample, size=10)
subset_posterior <- sample(mcmc_sample[[1]], size=10)
subset_prior <- runif(n=10, min = 0, max=1000)
x_axis <- seq(1:1000)#/1000
min_max= quantile(x=c(sapply(X=x_axis, FUN=log_likelihood, data=n_letters, power=1.0), sapply(X=x_axis, FUN=log_prior), sapply(X=x_axis, FUN=unnormalized_log_posterior, data=n_letters, power=1.0)), probs=c(0,1))
plot(x=x_axis, y=sapply(X=x_axis, FUN=log_likelihood, data=n_letters, power=power), t="l", lwd=4, col="red", ylim=c(min_max[1], min_max[2]), ylab="Value", xlab="lambda value", cex=2)
subset_posterior <- sample(mcmc_sample[[1]], size=10)
subset_prior <- runif(n=10, min = 0, max=1000)
x_axis <- seq(1:1000)#/1000
min_max= quantile(x=c(sapply(X=x_axis, FUN=log_likelihood, data=n_letters, power=1.0), sapply(X=x_axis, FUN=log_prior), sapply(X=x_axis, FUN=unnormalized_log_posterior, data=n_letters, power=1.0)), probs=c(0,1))
plot(x=x_axis, y=sapply(X=x_axis, FUN=log_likelihood, data=n_letters, power=1.0), t="l", lwd=4, col="red", ylim=c(min_max[1], min_max[2]), ylab="Value", xlab="lambda value", cex=2)
lines(x=x_axis, y=sapply(X=x_axis, FUN=log_prior), lwd=2, col="black")
lines(x=x_axis, y=sapply(X=x_axis, FUN=unnormalized_log_posterior, data=n_letters, power=1.0), lwd=2, col="orange")
legend("bottomleft", legend=c("log-likelihood", "log-prior", "log-posterior"), col=c("red", "black", "orange"), lwd=2)
points(x=subset_posterior, y=mean(min_max), col="orange", pch=20, cex=2)
subset_posterior <- sample(mcmc_sample[[1]], size=10)
subset_prior <- runif(n=10, min = 0, max=1000)
x_axis <- seq(1:1000)#/1000
min_max= quantile(x=c(sapply(X=x_axis, FUN=log_likelihood, data=n_letters, power=1.0), sapply(X=x_axis, FUN=log_prior), sapply(X=x_axis, FUN=unnormalized_log_posterior, data=n_letters, power=1.0)), probs=c(0,1))
plot(x=x_axis, y=sapply(X=x_axis, FUN=log_likelihood, data=n_letters, power=1.0), t="l", lwd=4, col="red", ylim=c(min_max[1], min_max[2]), ylab="Value", xlab="lambda value", cex=2)
lines(x=x_axis, y=sapply(X=x_axis, FUN=log_prior), lwd=2, col="black")
lines(x=x_axis, y=sapply(X=x_axis, FUN=unnormalized_log_posterior, data=n_letters, power=1.0), lwd=2, col="orange")
legend("bottomleft", legend=c("log-likelihood", "log-prior", "log-posterior"), col=c("red", "black", "orange"), lwd=2)
points(x=subset_posterior, y=rep(mean(min_max), length(subset_posterior)), col="orange", pch=20, cex=2)
points(x=subset_prior, y=rep(-100, length(subset_prior)), col="black", pch=20, cex=2)
print(subset_posterior)
summary(ss_samples)
summary(SS_samples)
posterior <- sample( MetropolisMCMC(data=n_letters, number_iterations=10000, likelihood_power=1.0, burnin_proportion=0.5, thining_proportion=0.01), size=10)
posterior <- sample( MetropolisMCMC(data=n_letters, number_iterations=10000, likelihood_power=1.0, burnin_proportion=0.5, thining_proportion=0.01)[[1]], size=10)
post_05 <- sample( MetropolisMCMC(data=n_letters, number_iterations=10000, likelihood_power=0.5, burnin_proportion=0.5, thining_proportion=0.01)[[1]], size=10)
post_025 <- sample( MetropolisMCMC(data=n_letters, number_iterations=10000, likelihood_power=0.25, burnin_proportion=0.5, thining_proportion=0.01)[[1]], size=10)
post_0125 <- sample( MetropolisMCMC(data=n_letters, number_iterations=10000, likelihood_power=0.125, burnin_proportion=0.5, thining_proportion=0.01)[[1]], size=10)
post_00625 <- sample( MetropolisMCMC(data=n_letters, number_iterations=10000, likelihood_power=0.0625, burnin_proportion=0.5, thining_proportion=0.01)[[1]], size=10)
x_axis <- seq(1:1000)#/1000
min_max= quantile(x=c(sapply(X=x_axis, FUN=log_likelihood, data=n_letters, power=1.0), sapply(X=x_axis, FUN=log_prior), sapply(X=x_axis, FUN=unnormalized_log_posterior, data=n_letters, power=1.0)), probs=c(0,1))
plot(x=x_axis, y=sapply(X=x_axis, FUN=log_likelihood, data=n_letters, power=1.0), t="l", lwd=4, col="red", ylim=c(min_max[1], min_max[2]), ylab="Value", xlab="lambda value", cex=2)
lines(x=x_axis, y=sapply(X=x_axis, FUN=log_prior), lwd=2, col="black")
lines(x=x_axis, y=sapply(X=x_axis, FUN=unnormalized_log_posterior, data=n_letters, power=1.0), lwd=2, col="orange")
legend("bottomleft", legend=c("log-likelihood", "log-prior", "log-posterior"), col=c("red", "black", "orange"), lwd=2)
points(x=posterior, y=rep(mean(min_max), length(posterior)), col="orange", pch=20, cex=2)
points(x=post_05, y=rep(mean(min_max)*0.5, length(posterior)), col="orange", pch=20, cex=2)
points(x=post_025, y=rep(mean(min_max)*0.25, length(posterior)), col="orange", pch=20, cex=2)
points(x=post_0125, y=rep(mean(min_max)*0.125, length(posterior)), col="orange", pch=20, cex=2)
points(x=post_00625, y=rep(mean(min_max)*0.0625, length(posterior)), col="orange", pch=20, cex=2)
min(vector_powers)
post_00625 <- sample( MetropolisMCMC(data=n_letters, number_iterations=10000, likelihood_power=2.154435e-07, burnin_proportion=0.5, thining_proportion=0.01)[[1]], size=10)
post_00625
post_0125
posterior <- sample( MetropolisMCMC(data=n_letters, number_iterations=10000, likelihood_power=1.0, burnin_proportion=0.5, thining_proportion=0.01)[[1]], size=10)
post_05 <- sample( MetropolisMCMC(data=n_letters, number_iterations=10000, likelihood_power=0.5, burnin_proportion=0.5, thining_proportion=0.01)[[1]], size=10)
post_025 <- sample( MetropolisMCMC(data=n_letters, number_iterations=10000, likelihood_power=0.005, burnin_proportion=0.5, thining_proportion=0.01)[[1]], size=10)
post_0125 <- sample( MetropolisMCMC(data=n_letters, number_iterations=10000, likelihood_power=0.00005, burnin_proportion=0.5, thining_proportion=0.01)[[1]], size=10)
post_00625 <- sample( MetropolisMCMC(data=n_letters, number_iterations=10000, likelihood_power=0.0000005, burnin_proportion=0.5, thining_proportion=0.01)[[1]], size=10)
x_axis <- seq(1:1000)#/1000
min_max= quantile(x=c(sapply(X=x_axis, FUN=log_likelihood, data=n_letters, power=1.0), sapply(X=x_axis, FUN=log_prior), sapply(X=x_axis, FUN=unnormalized_log_posterior, data=n_letters, power=1.0)), probs=c(0,1))
plot(x=x_axis, y=sapply(X=x_axis, FUN=log_likelihood, data=n_letters, power=1.0), t="l", lwd=4, col="red", ylim=c(min_max[1], min_max[2]), ylab="Value", xlab="lambda value", cex=2)
lines(x=x_axis, y=sapply(X=x_axis, FUN=log_prior), lwd=2, col="black")
lines(x=x_axis, y=sapply(X=x_axis, FUN=unnormalized_log_posterior, data=n_letters, power=1.0), lwd=2, col="orange")
legend("bottomleft", legend=c("log-likelihood", "log-prior", "log-posterior"), col=c("red", "black", "orange"), lwd=2)
points(x=posterior, y=rep(mean(min_max), length(posterior)), col="orange", pch=20, cex=2)
points(x=post_05, y=rep(mean(min_max)*0.5, length(posterior)), col="orange", pch=20, cex=2)
points(x=post_025, y=rep(mean(min_max)*0.25, length(posterior)), col="orange", pch=20, cex=2)
points(x=post_0125, y=rep(mean(min_max)*0.125, length(posterior)), col="orange", pch=20, cex=2)
points(x=post_00625, y=rep(mean(min_max)*0.0625, length(posterior)), col="orange", pch=20, cex=2)
x_axis <- seq(1:1000)#/1000
min_max= quantile(x=c(sapply(X=x_axis, FUN=log_likelihood, data=n_letters, power=1.0), sapply(X=x_axis, FUN=log_prior), sapply(X=x_axis, FUN=unnormalized_log_posterior, data=n_letters, power=1.0)), probs=c(0,1))
plot(x=x_axis, y=sapply(X=x_axis, FUN=log_likelihood, data=n_letters, power=1.0), t="l", lwd=4, col="red", ylim=c(min_max[1], min_max[2]), ylab="Value", xlab="lambda value", cex=2)
lines(x=x_axis, y=sapply(X=x_axis, FUN=log_prior), lwd=2, col="black")
lines(x=x_axis, y=sapply(X=x_axis, FUN=unnormalized_log_posterior, data=n_letters, power=1.0), lwd=2, col="orange")
legend("bottomleft", legend=c("log-likelihood", "log-prior", "log-posterior"), col=c("red", "black", "orange"), lwd=2)
points(x=posterior, y=rep(mean(min_max), length(posterior)), col="orange", pch=20, cex=2)
points(x=post_05, y=rep(mean(min_max)-0.2*mean(min_max), length(posterior)), col="orange", pch=20, cex=2)
points(x=post_025, y=rep(mean(min_max)*-0.4*mean(min_max), length(posterior)), col="orange", pch=20, cex=2)
points(x=post_0125, y=rep(mean(min_max)*-0.6*mean(min_max), length(posterior)), col="orange", pch=20, cex=2)
points(x=post_00625, y=rep(mean(min_max)*-0.8*mean(min_max), length(posterior)), col="orange", pch=20, cex=2)
x_axis <- seq(1:1000)#/1000
min_max= quantile(x=c(sapply(X=x_axis, FUN=log_likelihood, data=n_letters, power=1.0), sapply(X=x_axis, FUN=log_prior), sapply(X=x_axis, FUN=unnormalized_log_posterior, data=n_letters, power=1.0)), probs=c(0,1))
plot(x=x_axis, y=sapply(X=x_axis, FUN=log_likelihood, data=n_letters, power=1.0), t="l", lwd=4, col="red", ylim=c(min_max[1], min_max[2]), ylab="Value", xlab="lambda value", cex=2)
lines(x=x_axis, y=sapply(X=x_axis, FUN=log_prior), lwd=2, col="black")
lines(x=x_axis, y=sapply(X=x_axis, FUN=unnormalized_log_posterior, data=n_letters, power=1.0), lwd=2, col="orange")
legend("bottomleft", legend=c("log-likelihood", "log-prior", "log-posterior"), col=c("red", "black", "orange"), lwd=2)
points(x=posterior, y=rep(mean(min_max), length(posterior)), col="orange", pch=20, cex=2)
points(x=post_05, y=rep(mean(min_max)-0.2*mean(min_max), length(posterior)), col="orange", pch=20, cex=2)
points(x=post_025, y=rep(mean(min_max)-0.4*mean(min_max), length(posterior)), col="orange", pch=20, cex=2)
points(x=post_0125, y=rep(mean(min_max)-0.6*mean(min_max), length(posterior)), col="orange", pch=20, cex=2)
points(x=post_00625, y=rep(mean(min_max)-0.8*mean(min_max), length(posterior)), col="orange", pch=20, cex=2)
dim(SS_samples)
vector_powers <- build_vector_powers (number_of_stones = 20)
SS_samples <- steppingStoneSampling(vector_powers=vector_powers, data=n_letters, number_iterations=10000, burnin_proportion=0.1, thining_proportion=0.2)
vector_powers <- build_vector_powers (number_of_stones = 20)
SS_samples <- steppingStoneSampling(vector_powers=vector_powers, data=n_letters, number_iterations=10000, burnin_proportion=0.1, thining_proportion=0.2)
library(matrixStats)
n_letters <- c(13,17,14,10,13,16,14,14,11,14,9,14,13,10,11,12,17,15,23,16,13,14,12,16,15,19,14,11,15,14,17,20,27,21,12,6,18,10,8,12,11,14,14,15,16,17,12,13,17,10,16,20,15,12,24,10,17,14,14,13,15,12,14,17,9,16,27,10,16,9,15,11,16,11,17,17,11,20,23,12,18,26,12,17,16,12,11,16,21,19,20,19,15,15,7,14,12,12,15,10,19,19,17,15,17,20,17,17,11,11,17,16,15,12,16,17,14,18,15,15,10,17,12,16,22,20,23,16,11,19,16,22,13,14,11,10,19,16,19,15,16,16,16,19,14,19,14,10,7,11,12,9,13,18,23,13,16,11,15,13,15,19,16,21,14,14,14,12,15,16,18,15,15,13,15,19,11,17,13,9,13,16,16,13,13,13,18,21,14,14,13,8,21,20,15,20,10,16,18,14,21,15,20,15,15,9,16,16,11,19,12,31,19,18,13,11,14,14,11,10,11,12,13,17,14,14,25,17,18,16,18,11,23,23,14,14,11,17,11,12,18,15,15,13,16,18,15,16,14,11,11,17,18,14,20,17,16,13,12,14,14,18,16,21,16,15,18,19,22,16,15,10,12,11,9,18,11,13,5,13,16,14,12,23,19,14,17,11,17,18,17,16,11,22,18,20,11,12,9,8,12,12,17,16,12,20,19,15,9,14,11,13,13,23,16,10,17,14,20,11,20,15,20,15,19,19,16,15,14,18,24,18,12,16,10,18,16,19,13,13,13,22,13,15,17,17,20,18,18,12,13,14,17,15,17,20,18,22,23,13,16,15,18,10,19,12,14,19,14,19,23,19,22,8,14,20,22,14,13,13,9,11,13,14,16,16,16,14,16,24,11,10,14,14,14,18,15,11,12,15,16,13,8,13,21,19,17,18,10,14,14,16,14,11,14,12,15,9,17,17,21,11,8,22,18,18,23,20,14,10,15,10,18,12,10,18,17,18,18,9,15,18,15,15,17,15,18,16,9,16,15,10,18,18,19,8,18,17,10,11,17,12,14,16,14,10,10,20,16,11,15,14,15,21,15,21,16,17,18,12,14,10,13,17,12,14,26,23,20,12,21,17,11,12,12,11,15,19,15,12,15,12,21,13,19,17,18,17,11,22,17,13,11,16,16,10,17,14,17,18)
log_prior <- function (lambda) {
return (dunif(x=lambda, min=0, max=1000, log=TRUE))
}
log_likelihood <- function (data, lambda, power=1) {
return (sum(dpois(x=data, lambda=lambda, log=TRUE))*power)
}
likelihood <- function (data, lambda, power=1) {
return (prod(dpois(x=data, lambda=lambda, log=FALSE))^power)
}
unnormalized_log_posterior <- function (data, lambda, power=1) {
log_prior_value <- log_prior(lambda=lambda)
log_likelihood_value <- log_likelihood(data=data, lambda=lambda, power=power)
return(log_prior_value + log_likelihood_value)
}
plotDistributions <- function (power) {
x_axis <- seq(1:1000)#/1000
min_max= quantile(x=c(sapply(X=x_axis, FUN=log_likelihood, data=n_letters, power=1.0), sapply(X=x_axis, FUN=log_prior), sapply(X=x_axis, FUN=unnormalized_log_posterior, data=n_letters, power=1.0)), probs=c(0,1))
plot(x=x_axis, y=sapply(X=x_axis, FUN=log_likelihood, data=n_letters, power=power), t="l", lwd=4, col="red", ylim=c(min_max[1], min_max[2]), ylab="Value", xlab="lambda value", cex=2)
lines(x=x_axis, y=sapply(X=x_axis, FUN=log_prior), lwd=2, col="black")
lines(x=x_axis, y=sapply(X=x_axis, FUN=unnormalized_log_posterior, data=n_letters, power=power), lwd=2, col="orange")
legend("bottomleft", legend=c("log-likelihood", "log-prior", "log-posterior"), col=c("red", "black", "orange"), lwd=2)
}
plotDistributions(power=1.0)
lambda_sample <- seq(1:100000)/100
unnormalized_marginal_likelihood <- logSumExp(sapply(X=lambda_sample, FUN=log_likelihood, data=n_letters)) - log(length(lambda_sample))
print(unnormalized_marginal_likelihood)
# Function to propose a new parameter value, randomly drawn between 0 and 1000
propose_new_lambda_value <-function() {
return (runif(min=0, max=1000, n=1))
}
# Function to run Metropolis MCMC inference
MetropolisMCMC <- function (data, number_iterations, burnin_proportion=0.5, thining_proportion=0.1, likelihood_power=1.0) {
current_parameter_value <- propose_new_lambda_value()
record_parameter <- c()
record_parameter <- c(record_parameter,current_parameter_value)
#print(paste("Initial parameter value for the MCMC: ", current_parameter_value, sep=""))
current_log_posterior <- unnormalized_log_posterior(data = data, lambda = current_parameter_value, power=likelihood_power)
#print(paste("Initial probability of the model: ", current_log_posterior, sep=""))
record_log_posterior <- c()
record_log_posterior <- c(record_log_posterior, current_log_posterior)
# We also record the likelihood:
current_log_likelihood <- log_likelihood(data = data, lambda = current_parameter_value, power=likelihood_power)
record_log_likelihood <- c()
record_log_likelihood <- c(record_log_likelihood, current_log_likelihood)
for (i in 1:number_iterations) {
acceptance_threshold <- runif(min=0, max=1, n=1)
proposed_parameter_value <- propose_new_lambda_value()
proposed_log_posterior = unnormalized_log_posterior(data = data, lambda = proposed_parameter_value, power=likelihood_power)
# print(paste0(proposed_log_posterior, " vs ", current_log_posterior))
if (exp(proposed_log_posterior - current_log_posterior) > acceptance_threshold) {
current_parameter_value <- proposed_parameter_value
current_log_posterior <- proposed_log_posterior
current_log_likelihood <- log_likelihood(data = data, lambda = current_parameter_value, power=likelihood_power)
}
record_parameter <- c(record_parameter, current_parameter_value)
record_log_posterior <-c(record_log_posterior, current_log_posterior)
record_log_likelihood <- c(record_log_likelihood, current_log_likelihood)
}
to_discard_as_burnin <- floor(burnin_proportion * number_iterations)
num_samples_left <- number_iterations - to_discard_as_burnin
between_samples <- floor(num_samples_left / (num_samples_left * thining_proportion))
record_parameter <- record_parameter[(to_discard_as_burnin+1):number_iterations][seq(from=1, to=num_samples_left, by=between_samples)]
record_log_posterior <- record_log_posterior[(to_discard_as_burnin+1):number_iterations][seq(from=1, to=num_samples_left, by=between_samples)]
record_log_likelihood <- record_log_likelihood[(to_discard_as_burnin+1):number_iterations][seq(from=1, to=num_samples_left, by=between_samples)]
return (list(record_parameter, record_log_posterior, record_log_likelihood))
}
mcmc_sample <- MetropolisMCMC(data=n_letters, number_iterations=10000, likelihood_power=1.0, burnin_proportion=0.5, thining_proportion=0.01)
harmonic_mean <- function(mcmc_sample) {
loglks <- mcmc_sample[[3]]
min_loglk <- min(loglks)
scaled_loglks <- loglks - min_loglk + 1
number_of_samples <- length(loglks)
marginal_lk <- log(number_of_samples) - log( sum(exp(-scaled_loglks))) + min_loglk - 1
return(marginal_lk)
}
harmonic_mean(mcmc_sample)
subset_posterior <- sample(mcmc_sample[[1]], size=10)
subset_prior <- runif(n=10, min = 0, max=1000)
x_axis <- seq(1:1000)#/1000
min_max= quantile(x=c(sapply(X=x_axis, FUN=log_likelihood, data=n_letters, power=1.0), sapply(X=x_axis, FUN=log_prior), sapply(X=x_axis, FUN=unnormalized_log_posterior, data=n_letters, power=1.0)), probs=c(0,1))
plot(x=x_axis, y=sapply(X=x_axis, FUN=log_likelihood, data=n_letters, power=1.0), t="l", lwd=4, col="red", ylim=c(min_max[1], min_max[2]), ylab="Value", xlab="lambda value", cex=2)
lines(x=x_axis, y=sapply(X=x_axis, FUN=log_prior), lwd=2, col="black")
lines(x=x_axis, y=sapply(X=x_axis, FUN=unnormalized_log_posterior, data=n_letters, power=1.0), lwd=2, col="orange")
legend("bottomleft", legend=c("log-likelihood", "log-prior", "log-posterior"), col=c("red", "black", "orange"), lwd=2)
points(x=subset_posterior, y=rep(mean(min_max), length(subset_posterior)), col="orange", pch=20, cex=2)
points(x=subset_prior, y=rep(-100, length(subset_prior)), col="black", pch=20, cex=2)
par(mfrow=c(5,1))
plotDistributions(1.0)
plotDistributions(0.5)
plotDistributions(0.25)
plotDistributions(0.125)
plotDistributions(0.06275)
posterior <- sample( MetropolisMCMC(data=n_letters, number_iterations=10000, likelihood_power=1.0, burnin_proportion=0.5, thining_proportion=0.01)[[1]], size=10)
post_05 <- sample( MetropolisMCMC(data=n_letters, number_iterations=10000, likelihood_power=0.5, burnin_proportion=0.5, thining_proportion=0.01)[[1]], size=10)
post_025 <- sample( MetropolisMCMC(data=n_letters, number_iterations=10000, likelihood_power=0.005, burnin_proportion=0.5, thining_proportion=0.01)[[1]], size=10)
post_0125 <- sample( MetropolisMCMC(data=n_letters, number_iterations=10000, likelihood_power=0.00005, burnin_proportion=0.5, thining_proportion=0.01)[[1]], size=10)
post_00625 <- sample( MetropolisMCMC(data=n_letters, number_iterations=10000, likelihood_power=0.0000005, burnin_proportion=0.5, thining_proportion=0.01)[[1]], size=10)
x_axis <- seq(1:1000)#/1000
min_max= quantile(x=c(sapply(X=x_axis, FUN=log_likelihood, data=n_letters, power=1.0), sapply(X=x_axis, FUN=log_prior), sapply(X=x_axis, FUN=unnormalized_log_posterior, data=n_letters, power=1.0)), probs=c(0,1))
plot(x=x_axis, y=sapply(X=x_axis, FUN=log_likelihood, data=n_letters, power=1.0), t="l", lwd=4, col="red", ylim=c(min_max[1], min_max[2]), ylab="Value", xlab="lambda value", cex=2)
lines(x=x_axis, y=sapply(X=x_axis, FUN=log_prior), lwd=2, col="black")
lines(x=x_axis, y=sapply(X=x_axis, FUN=unnormalized_log_posterior, data=n_letters, power=1.0), lwd=2, col="orange")
legend("bottomleft", legend=c("log-likelihood", "log-prior", "log-posterior"), col=c("red", "black", "orange"), lwd=2)
points(x=posterior, y=rep(mean(min_max), length(posterior)), col="orange", pch=20, cex=2)
points(x=post_05, y=rep(mean(min_max)-0.2*mean(min_max), length(posterior)), col="orange", pch=20, cex=2)
points(x=post_025, y=rep(mean(min_max)-0.4*mean(min_max), length(posterior)), col="orange", pch=20, cex=2)
points(x=post_0125, y=rep(mean(min_max)-0.6*mean(min_max), length(posterior)), col="orange", pch=20, cex=2)
points(x=post_00625, y=rep(mean(min_max)-0.8*mean(min_max), length(posterior)), col="orange", pch=20, cex=2)
steppingStoneSampling <- function (vector_powers, data, number_iterations, burnin_proportion=0.5, thining_proportion=0.1) {
number_of_stones = length(vector_powers)
number_of_samples_per_stone = floor(number_iterations - floor(burnin_proportion*number_iterations)) * thining_proportion
sampled_values <-matrix(rep(number_of_stones*number_of_samples_per_stone), nrow=number_of_stones, ncol=number_of_samples_per_stone, byrow=TRUE)
for (i in 1:number_of_stones) {
sampled_values[i,] <- MetropolisMCMC(data, number_iterations, burnin_proportion=0.5, thining_proportion=0.1, likelihood_power=vector_powers[i])[[2]]
}
return(sampled_values)
}
compute_marginal_lk_from_SS_samples <- function (ss_samples) {
number_of_stones = dim(ss_samples)[1]
number_of_samples = dim(ss_samples)[2]
c_values <- rep(0, number_of_stones)
for (i in 1:number_of_stones) {
c_values[i] <- logSumExp(ss_samples[i,])
}
logratios <- rep(0, number_of_stones-1)
for (i in 1:(number_of_stones-1)) {
logratios[i] <- c_values[i+1]-c_values[i]
}
return(sum(logratios))
}
build_vector_powers <- function (alpha=0.3, beta=1.0, number_of_stones=10) {
vector_powers <- rep(0.0, 10)
for (i in 1:number_of_stones) {
vector_powers[i]<-(i/number_of_stones)^(beta/alpha)
}
return(vector_powers)
}
vector_powers <- build_vector_powers ()
SS_samples <- steppingStoneSampling(vector_powers=vector_powers, data=n_letters, number_iterations=1000, burnin_proportion=0.5, thining_proportion=0.1)
compute_marginal_lk_from_SS_samples(SS_samples)
SS_samples <- steppingStoneSampling(vector_powers=vector_powers, data=n_letters, number_iterations=10000, burnin_proportion=0.5, thining_proportion=0.1)
compute_marginal_lk_from_SS_samples(SS_samples)
vector_powers <- build_vector_powers (number_of_stones = 100)
SS_samples <- steppingStoneSampling(vector_powers=vector_powers, data=n_letters, number_iterations=1000, burnin_proportion=0.5, thining_proportion=0.1)
compute_marginal_lk_from_SS_samples(SS_samples)
vector_powers <- build_vector_powers (number_of_stones = 100)
SS_samples <- steppingStoneSampling(vector_powers=vector_powers, data=n_letters, number_iterations=10000, burnin_proportion=0.5, thining_proportion=0.1)
compute_marginal_lk_from_SS_samples(SS_samples)
steppingStoneSampling <- function (vector_powers, data, number_iterations, burnin_proportion=0.5, thining_proportion=0.1) {
number_of_stones = length(vector_powers)
number_of_samples_per_stone = floor(number_iterations - floor(burnin_proportion*number_iterations)) * thining_proportion
sampled_values <-matrix(rep(number_of_stones*number_of_samples_per_stone), nrow=number_of_stones, ncol=number_of_samples_per_stone, byrow=TRUE)
for (i in 1:number_of_stones) {
sampled_values[i,] <- MetropolisMCMC(data, number_iterations, burnin_proportion=number_iterations, thining_proportion=thining_proportion, likelihood_power=vector_powers[i])[[2]]
}
return(sampled_values)
}
compute_marginal_lk_from_SS_samples <- function (ss_samples) {
number_of_stones = dim(ss_samples)[1]
number_of_samples = dim(ss_samples)[2]
c_values <- rep(0, number_of_stones)
for (i in 1:number_of_stones) {
c_values[i] <- logSumExp(ss_samples[i,])
}
logratios <- rep(0, number_of_stones-1)
for (i in 1:(number_of_stones-1)) {
logratios[i] <- c_values[i+1]-c_values[i]
}
return(sum(logratios))
}
vector_powers <- build_vector_powers (number_of_stones = 20)
SS_samples <- steppingStoneSampling(vector_powers=vector_powers, data=n_letters, number_iterations=10000, burnin_proportion=0.1, thining_proportion=0.2)
steppingStoneSampling <- function (vector_powers, data, number_iterations, burnin_proportion=0.5, thining_proportion=0.1) {
number_of_stones = length(vector_powers)
number_of_samples_per_stone = floor(number_iterations - floor(burnin_proportion*number_iterations)) * thining_proportion
sampled_values <-matrix(rep(number_of_stones*number_of_samples_per_stone), nrow=number_of_stones, ncol=number_of_samples_per_stone, byrow=TRUE)
for (i in 1:number_of_stones) {
sampled_values[i,] <- MetropolisMCMC(data, number_iterations, burnin_proportion=burnin_proportion, thining_proportion=thining_proportion, likelihood_power=vector_powers[i])[[2]]
}
return(sampled_values)
}
compute_marginal_lk_from_SS_samples <- function (ss_samples) {
number_of_stones = dim(ss_samples)[1]
number_of_samples = dim(ss_samples)[2]
c_values <- rep(0, number_of_stones)
for (i in 1:number_of_stones) {
c_values[i] <- logSumExp(ss_samples[i,])
}
logratios <- rep(0, number_of_stones-1)
for (i in 1:(number_of_stones-1)) {
logratios[i] <- c_values[i+1]-c_values[i]
}
return(sum(logratios))
}
vector_powers <- build_vector_powers (number_of_stones = 20)
SS_samples <- steppingStoneSampling(vector_powers=vector_powers, data=n_letters, number_iterations=10000, burnin_proportion=0.1, thining_proportion=0.2)
compute_marginal_lk_from_SS_samples(SS_samples)
vector_powers <- build_vector_powers (number_of_stones = 100)
SS_samples <- steppingStoneSampling(vector_powers=vector_powers, data=n_letters, number_iterations=100000, burnin_proportion=0.1, thining_proportion=0.2)
compute_marginal_lk_from_SS_samples(SS_samples)
